{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "from glob import glob\n",
    "import shutil\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input_folder_path_dog = \\'/Users/kantasaito/Desktop/GitHub/MachineLearning/ImageClassification/archive/training_set/training_set/dogs\\'\\ninput_folder_path_cat = \\'/Users/kantasaito/Desktop/GitHub/MachineLearning/ImageClassification/archive/training_set/training_set/cats\\'\\ndog_contents = os.listdir(input_folder_path_dog)\\ncat_contents = os.listdir(input_folder_path_cat)\\n\\noutput_folder_path_dog = \\'/Users/kantasaito/Desktop/GitHub/MachineLearning/ImageClassification/archive/training_set/training_set/dogs_resized\\'\\noutput_folder_path_cat = \\'/Users/kantasaito/Desktop/GitHub/MachineLearning/ImageClassification/archive/training_set/training_set/cats_resized\\'\\ncat_dog_output_train = \\'/Users/kantasaito/Desktop/GitHub/MachineLearning/ImageClassification/archive/training_set/training_set/cats_dogs_resized_train\\'\\ncat_dog_output_test = \\'/Users/kantasaito/Desktop/GitHub/MachineLearning/ImageClassification/archive/test_set/test_set/cats_dogs_resized_test\\'\\ntarget_size = (200, 200)\\nos.makedirs(output_folder_path_dog, exist_ok=True)\\nos.makedirs(output_folder_path_cat, exist_ok=True)\\nos.makedirs(cat_dog_output_train, exist_ok=True)\\nos.makedirs(cat_dog_output_test, exist_ok=True)\\n\\nfor dog_filename in dog_contents:\\n    img_path = os.path.join(input_folder_path_dog, dog_filename)\\n    try:\\n        img = cv2.imread(img_path)\\n        img_resized = cv2.resize(img, target_size)\\n        output_path = os.path.join(output_folder_path_dog, dog_filename)\\n        output_path_train = os.path.join(cat_dog_output_train, dog_filename)\\n        output_path_test = os.path.join(cat_dog_output_test, dog_filename)\\n        cv2.imwrite(output_path, img_resized)\\n        cv2.imwrite(output_path_train, img_resized)\\n        cv2.imwrite(output_path_test, img_resized)\\n        print(f\"Resized: {output_path}\")\\n    except Exception as e:\\n        print(f\"Error processing {img_path}: {e}\")\\n\\nfor cat_filename in cat_contents:\\n    img_path = os.path.join(input_folder_path_cat, cat_filename)\\n    try:\\n        img = cv2.imread(img_path)\\n        img_resized = cv2.resize(img, target_size)\\n        output_path = os.path.join(output_folder_path_cat, cat_filename)\\n        output_path_train = os.path.join(cat_dog_output_train, cat_filename)\\n        output_path_test = os.path.join(cat_dog_output_test, cat_filename)\\n        cv2.imwrite(output_path, img_resized)\\n        cv2.imwrite(output_path_train, img_resized)\\n        cv2.imwrite(output_path_test, img_resized)\\n        print(f\"Resized: {output_path}\")\\n    except Exception as e:\\n        print(f\"Error processing {img_path}: {e}\")'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"input_folder_path_dog = '/Users/kantasaito/Desktop/GitHub/MachineLearning/ImageClassification/archive/training_set/training_set/dogs'\n",
    "input_folder_path_cat = '/Users/kantasaito/Desktop/GitHub/MachineLearning/ImageClassification/archive/training_set/training_set/cats'\n",
    "dog_contents = os.listdir(input_folder_path_dog)\n",
    "cat_contents = os.listdir(input_folder_path_cat)\n",
    "\n",
    "output_folder_path_dog = '/Users/kantasaito/Desktop/GitHub/MachineLearning/ImageClassification/archive/training_set/training_set/dogs_resized'\n",
    "output_folder_path_cat = '/Users/kantasaito/Desktop/GitHub/MachineLearning/ImageClassification/archive/training_set/training_set/cats_resized'\n",
    "cat_dog_output_train = '/Users/kantasaito/Desktop/GitHub/MachineLearning/ImageClassification/archive/training_set/training_set/cats_dogs_resized_train'\n",
    "cat_dog_output_test = '/Users/kantasaito/Desktop/GitHub/MachineLearning/ImageClassification/archive/test_set/test_set/cats_dogs_resized_test'\n",
    "target_size = (200, 200)\n",
    "os.makedirs(output_folder_path_dog, exist_ok=True)\n",
    "os.makedirs(output_folder_path_cat, exist_ok=True)\n",
    "os.makedirs(cat_dog_output_train, exist_ok=True)\n",
    "os.makedirs(cat_dog_output_test, exist_ok=True)\n",
    "\n",
    "for dog_filename in dog_contents:\n",
    "    img_path = os.path.join(input_folder_path_dog, dog_filename)\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        img_resized = cv2.resize(img, target_size)\n",
    "        output_path = os.path.join(output_folder_path_dog, dog_filename)\n",
    "        output_path_train = os.path.join(cat_dog_output_train, dog_filename)\n",
    "        output_path_test = os.path.join(cat_dog_output_test, dog_filename)\n",
    "        cv2.imwrite(output_path, img_resized)\n",
    "        cv2.imwrite(output_path_train, img_resized)\n",
    "        cv2.imwrite(output_path_test, img_resized)\n",
    "        print(f\"Resized: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "for cat_filename in cat_contents:\n",
    "    img_path = os.path.join(input_folder_path_cat, cat_filename)\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        img_resized = cv2.resize(img, target_size)\n",
    "        output_path = os.path.join(output_folder_path_cat, cat_filename)\n",
    "        output_path_train = os.path.join(cat_dog_output_train, cat_filename)\n",
    "        output_path_test = os.path.join(cat_dog_output_test, cat_filename)\n",
    "        cv2.imwrite(output_path, img_resized)\n",
    "        cv2.imwrite(output_path_train, img_resized)\n",
    "        cv2.imwrite(output_path_test, img_resized)\n",
    "        print(f\"Resized: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer = 'he_uniform', padding = 'same', input_shape=(200,200, 3)))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Conv2D(62, (3, 3), activation='relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = SGD(learning_rate = 0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss ='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_summary(history):\n",
    "    plt.subplot(211)\n",
    "    plt.title(\"Cross Entropy Loss\")\n",
    "    plt.plot(history.history['loss'], color='red', label='train')\n",
    "    plt.plot(history.history['value_loss'], color='blue', label='test')\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['accuracy'], color='red', label='train')\n",
    "    plt.plot(history.history['value_accuracy'], color='blue', label='test')\n",
    "    filename= sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_plot.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The PyDataset has length 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m> \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (acc \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100.0\u001b[39m))\n\u001b[1;32m     11\u001b[0m     test_summary(history)\n\u001b[0;32m---> 12\u001b[0m run_test()\n",
      "Cell \u001b[0;32mIn[46], line 8\u001b[0m, in \u001b[0;36mrun_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m training \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(cat_dog_output_train, class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m))\n\u001b[1;32m      7\u001b[0m testing \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(cat_dog_output_test, class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(training, steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(training), validation_data\u001b[38;5;241m=\u001b[39mtesting, validation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(testing), epochs\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      9\u001b[0m _, acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(testing, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(testing), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m> \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (acc \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100.0\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:295\u001b[0m, in \u001b[0;36mPyDatasetAdapter.get_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m     batches \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_standardize_batch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpy_dataset[i])\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples)\n\u001b[1;32m    293\u001b[0m     ]\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batches) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 295\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe PyDataset has length 0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_signature \u001b[38;5;241m=\u001b[39m data_adapter_utils\u001b[38;5;241m.\u001b[39mget_tensor_spec(batches)\n\u001b[1;32m    298\u001b[0m ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_generator(\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator,\n\u001b[1;32m    300\u001b[0m     output_signature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_signature,\n\u001b[1;32m    301\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: The PyDataset has length 0"
     ]
    }
   ],
   "source": [
    "def run_test():\n",
    "    cat_dog_output_train = '/Users/kantasaito/Desktop/GitHub/MachineLearning/ImageClassification/archive/training_set/training_set/cats_dogs_resized_train'\n",
    "    cat_dog_output_test = '/Users/kantasaito/Desktop/GitHub/MachineLearning/ImageClassification/archive/test_set/test_set/cats_dogs_resized_test'\n",
    "    model = make_model()\n",
    "    datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    training = datagen.flow_from_directory(cat_dog_output_train, class_mode='binary',batch_size=64, target_size=(200, 200))\n",
    "    testing = datagen.flow_from_directory(cat_dog_output_test, class_mode='binary', batch_size=64, target_size=(200, 200))\n",
    "    history = model.fit(training, steps_per_epoch=len(training), validation_data=testing, validation_steps=len(testing), epochs= 20, verbose=0)\n",
    "    _, acc = model.evaluate(testing, steps=len(testing), verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    test_summary(history)\n",
    "run_test()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
